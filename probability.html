<html>
<!-- THIS FILE WAS GENERATED BY A SCRIPT: DO NOT EDIT IT! -->
    <head>
        <link href="style.css" rel="stylesheet" type="text/css"/>
        <title>
            Discrete Probability
        </title>
    </head>

    <body>

    <div id="header">
        <div id="logo">
            <img
            src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/6n-graf.svg/250px-6n-graf.svg.png"
            height="56" width="84"
            max-height=100%>
        </div>
        <div id="user-tools">
            <a href="index.html">Home</a>
            &nbsp; &nbsp; 
            <a href="about.html">About</a>
        </div>
    </div>


        <h1 class="chap-title">
            Discrete Probability
        </h1>
            <div style="text-align:center">
                <figure class="lead-figure">
                    <img
                        src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/PascalTriangleAnimated2.gif/220px-PascalTriangleAnimated2.gif">
                </figure>
            </div>
            
            <details>
                <summary class="sum1">
                An Introduction to Discrete Probability 
                </summary>
                <details>
                    <summary class="sum2">
                        Finite Probability
                    </summary>
                    <p>
                        An experiment is a procedure that 
                        yields one of a given set of 
                        possible outcomes. The sample space of 
                        the experiment is the set of possible 
                        outcomes. An event is a subset 
                        of the sample space. 
                    </p>
                    <p class="def">
                        DEFINITION
                    </p>
                    <p>If <i>S</i> is a finite nonempty sample space of equally likely outcomes, and <i>E</i> is an event, that
                        is, a subset of <i>S</i>, then the probability of <i>E</i> is p(E) = |<i>E</i>| | |<i>S</i>|</p>
                </details>
                <details>
                    <summary class="sum2">
                        Probabilities of Complements and Unions of Events
                    </summary>
                    <details>
                        <summary class="sum3">
                            THEOREM 1
                        </summary>
                          <p>Let <i>E</i> be an event in a sample space <i>S</i>. The probability of the event <i>E</i> = <i>S</i> − <i>E</i>, the complementary
                              event of <i>E</i>, is given by p(E) = 1 − p(E).</p>
                    </details>
                    <details>
                        <summary class="sum3">
                          Example
                        </summary>
                          <p>What is the probability that when two dice are rolled, the sum of the numbers on the two dice is 7?<br></p>
                     <details>
                         <summary class="sum4">
                           Answer
                         </summary>
                            <p> There are a total of 36 equally likely possible outcomes when two dice are rolled.There are six successful outcomes, namely, 
                               (1, 6), (2, 5), (3, 4),<br> (4, 3), (5, 2), and (6, 1), where the values of the first and second dice are represented by an ordered pair.
                                Hence, the probability that a seven comes <br>up when two fair dice are rolled is 6/36 = 1/6.</p>
                      </details>
                     </details>
                     <details>
                         <summary class="sum3">
                           Example
                         </summary>
                           <p>Find the probability that a hand of five cards in poker contains four cards of one kind<br></p>
                      <details>
                          <summary class="sum4">
                            Answer
                          </summary>
                             <p> By the product rule, the number of hands of five cards with four cards of one kind is the product of the number of ways
                                  to pick one kind, the number of ways to pick the four of this kind out of the four in the deck of this kind,and the number of ways
                                 to pick the fifth card.This is C(13, 1) C(4, 4) C(48, 1).By Example 11 in Section 6.3 there are C(52, 5) different hands of five cards. Hence, the
                                probability that a hand contains four cards of one kind is (C(13, 1) C(4, 4) C(48, 1))/ C(52, 5) = (13 · 1 · 48) / 2,598,960 ≈ 0.00024.</p>
                       </details>
                      </details>
                    <details>
                        <summary class="sum3">
                            THEOREM 2
                        </summary>
                           <p>Let <i>E1 </i>and <i>E2</i> be events in the sample space <i>S</i>. Then <i>p(E1 ∪ E2) = p(E1) + p(E2) − p(E1 ∩ E2).</i></p>
                    </details>
                    <details>
                        <summary class="sum3">
                          Example
                        </summary>
                          <p>What is the probability that a positive integer selected at random from the set of positive integers not exceeding 100 is divisible by either 2 or 5?<br></p>
                     <details>
                         <summary class="sum4">
                           Answer
                         </summary>
                            <p> Let <i>E1</i> be the event that the integer selected at random is divisible by 2, and let <i>E2</i> be the event that <br> it is divisible by 5.</p><p> Then <i>E1</i> ∪ <i>E2</i> is the event that it is divisible by either 2 or 5.</p><p>Also,<i> E1</i> ∩<i> E2</i> is the event that it is divisible by both 2 and 5, <br>or equivalently, that it is divisible by 10.</p><p> Because <i>|E1| = 50</i>, <i>|E2| = 20</i>, and <i> |E1 ∩ E2| = 10 </i>, it follows that <i>p(E1 ∪ E2) = p(E1) + p(E2) − p(E1 ∩ E2)= 50/100 + 20/100 - 10/100= 3/5.</i></p>
                      </details>
                     </details>
                </details>

                <details>
                    <summary class="sum2">
                        Probabilistic Reasoning
                    </summary>
                    <p>Probabilistic reasoning is using logic and probability to handle uncertain situations. </p> <p>An example of probabilistic reasoning is using past situations and                          statistics to predict an outcome.</p><p>It is used to define which of two events is more likely.Analyzing <br>the probabilities of such events can be tricky. The below                       Example describes a problem of this type.</p>
                </details>
                <details>
                    <summary class="sum3">
                        The Monty Hall Problem Video
                    </summary>

                    <figure>
                        <iframe width="560" height="315"
                            src="https://www.youtube.com/embed/4Lb-6rxZxx0"
                            frameborder="0" allowfullscreen>
                        </iframe>
                        <figcaption>
                        </figcaption>
                    </figure>
                </details>

            </details>

            <details>
                <summary class="sum1">
                   Probability Theory 
                </summary>
                <summary class="sum2">
                   Overview
                </summary>
                <p>
                 We defined probability of an Event E as the number of outcomes in E divided by total number of outcomes.This definition assumes that outcomes are equally likely.
               </p>
                <p>
                However,many experiments have outcomes that are not equally likely. For  instance, a coin may be biased so that it comes up heads twice as often as tails.
                </p>
                <p> In this section we will study how to define probabilities where outcomes are not equally likely.</p>
                <details>
                    <summary class="sum2">
                        Assigning Probabilities
                    </summary>
                 <p>Let S be the sample space of an experiment with a finite or countable number of outcomes.We assign a probability p(s) to each outcome s.</p>
                 <p>We require that two conditions be met:</p>
                     <ol class="nested">
                       <li>0 &le; p(s) &le; for each s∈S </li>
                      <li><b>&sum;</b><sub> s∈S </sub>p(s)=1</li>
                     </ol>
                    <p>The function p from the set of all outcomes of the sample space S is called a probability distribution.</p><p>The probability p(s) assigned to an outcome s should                          equal the limit of the number of times s occurs divided by the number of times the experiment is performed,as this number grows without bound.</p>
                    <p class="def">
                        DEFINITION1
                    </p>
                <p>Consider a set <i>S</i> with n elements,then,the probability of each element of <i>S</i> considering uniform distribution is 1/n</p>
                </details>
                <details>
                    <summary class="sum2">
                        Probabilities of Complements and 
                        Unions of Events
                    </summary>

                    <p>
                        Complements:
                        <br />
                        p(<span class="over"><i>E</i></span>)
                            = 1 - <i>p</i>(<i>E</i>)
                    </p>

                    <p class="def">
                            THEOREM 1
                    </p>
                    <p>
                        The probability of any event composed of a
                        sequence of disjoint events is just the sum of 
                        the individual probabilities.
                    </p>

                    <p class="def">
                            THEOREM 2
                    </p>
                    <p>
                        If <i>E</i> and <i>F</i> are events in the 
                        sample space <i>S</i>, then:
                        <br />
                        <i>p</i>(<i>E</i> &cup; <i>F</i>)
                        = <i>p</i>(<i>E</i>) + <i>p</i>(<i>F</i>)
                        &minus; <i>p</i>(<i>E</i> &cap; <i>F</i>)
                    </p>

                </details>
                <details>
                    <summary class="sum2">
                        Conditional Probability
                    </summary>
                    <p class="def">
                            DEFINITION 3
                    </p>

                    <p>
                     The <i>conditional probability</i> of
                     event <i>E</i> given event <i>F</i> has
                     occurred is defined as:
                    </p>

                    <figure>
                        <img src="graphics/CondProb.gif">
                        <figcaption>
                        </figcaption>
                    </figure>

                    <figure>
                        <img
                        src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/White_shark.jpg/240px-White_shark.jpg">
                        <figcaption>
                            When the shark bites, with his teeth big...
                        </figcaption>
                    </figure>
                    <p>
                        Let's analyze with our shark example:
                        <br />
                        <i>E</i> = "bitten by shark" (imagine it's .0005)
                        <br />
                        <i>F</i> = "shark present" (imagine it's .001)
                        <br />
                        And <i>E</i> &cap; <i>F</i> = .0005
                        <br />
                        Therefore, <i>p</i>(<i>E</i> | <i>F</i>) = .5
                        <br />
                        Or, "Half the time, if there is a shark around, it
                        bites someone."
                    </p>
                </details>
                <details>
                    <summary class="sum2">
                        Independence
                    </summary>
                    <p class="def">
                        DEFINITION 4
                    </p>

                    <p>
                        Events <i>E</i> and <i>F</i> are <i>independent</i>
                        if and only if <i>p</i>(<i>E</i> &cap; <i>F</i>) 
                        = <i>p</i>(<i>E</i>)<i>p</i>(<i>F</i>)
                    </p>

                    <p>
                        Notice how this was <i>not</i> the case with the shark
                        attacks! <i>Given</i> a shark is around, the
                        probability of a shark bite is much higher than
                        <i>p</i>(<i>E</i>)<i>p</i>(<i>F</i>) (which was .0000005).
                        This would not be
                        true if <i>F</i> were, say, "UFO present."
                    </p>

                    <p>
                        <b>Pairwise independence versus mutual independence:</b>
                        <br />
                        The best way to understand this difference is to
                        consider a situation like this, with two coin tosses:
                        <br />
                        Event <i>A</i> is both tosses are the same.
                        <br />
                        Event <i>B</i> is the first toss is heads.
                        <br />
                        Event <i>C</i> is the second toss is heads.
                        <br />
                        Notice that if <i>B</i> and <i>C</i> both occur, or 
                        both don't occur, <i>A</i> occured for sure.
                        And if only one of <i>B</i> and <i>C</i> occured, 
                        <i>A</i> didn't occur for sure.
                        <br />
                        Nevertheless, any two pairs of these events, taken on
                        their own, <i>are</i> independent.
                    </p>

                    <ul class="nested">
                        <li>
                        <a
                            href="https://en.wikipedia.org/wiki/Pairwise_independence#Example">
                            Example for pairwise independence versus mutual
                            independence
                        </a>
                        </li>
                        <li>
                            <a
                                href="https://www.khanacademy.org/math/precalculus/prob-comb/dependent-events-precalc/v/independent-events-1">
                                Khan Academy on independent events
                            </a>
                        </li>
                    </ul>

                </details>
                <details>
                    <summary class="sum2">
                        Bernoulli Trials and the Binomial Distribution
                    </summary>
                    <p>
                     <b>Bernoulli trial</b>: an experiment with only two
                     possible outcomes. (The patient lives, or the patient
                     dies.)
                     <br />
                     <i>p</i> + <i>q</i> = 1
                    </p>

                    <p>
                    Many problems can be solved by determining
                    the probability
                    of <i>k</i> successes when an
                    experiment consists of <i>n</i> mutually
                    independent Bernoulli trials.
                    (Bernoulli trials are
                    mutually independent if the conditional probability of
                    success on any given trial is <i>p</i>,
                    given any information
                    whatsoever about the outcomes of the other trials.) 
                    </p>

                    <p class="def">
                        THEOREM 2
                    </p>
                    <p>
                     The probability of exactly <i>k</i> successes in
                     <i>n</i> independent
                     Bernoulli trials, with probability of success <i>p</i> and
                     probability of failure <i>q</i> = 1
                     &minus; <i>p</i>, is

                     <i>C</i>(<i>n</i>, <i>k</i>)<i>p</i><sup><i>k</i></sup><i>q</i><sup><i>n</i>&minus;<i>k</i></sup>
                    </p>

                    <p>
                        <b>Example:</b> Suppose that the probability that a 0
                        bit is generated is 0.9, that the probability that a 1
                        bit is generated is 0.1, and that bits are generated
                        independently. What is the probability that exactly
                        eight 0 bits are generated when 10 bits are generated?
                        <br />
                        <b>Answer:</b>
                        <i>C</i>(10, 8)(0.9)<sup>8</sup>(0.1)<sup>2</sup>
                        = 0.1937102445
                    </p>

                </details>
                <details>
                    <summary class="sum2">
                        Random Variables
                    </summary>
                    <p class="def">
                        DEFINITION 6
                    </p>
                    <p>
                        A <i>random variable</i> is a function from
                        the sample space of an experiment to the set
                        of real numbers. A random variable assigns a
                        real number to each possible outcome.
                        <br />
                        <b>Example</b>: Let <i>X</i>(<i>t</i>) be the
                        number of heads that appear in three coin tosses.
                        Then, <i>X</i>(HHH) = 3, <i>X</i>(HHT) = 2,
                        and so on.
                    </p>

                    <p class="def">
                        DEFINITION 7
                    </p>
                    
                    <p>
                        The <i>distribution</i> of a random variable is the
                        complete set of probabilities for each possible 
                        value of the variable.
                        <br />
                        <b>Example</b>: In the above case of three coin tosses,
                        <i>P</i>(<i>X</i> = 3) = 1/8, <i>P</i>(<i>X</i> = 2) =
                        3/8, and so on.
                        <br />
                        We will study how to <i>use</i> random variables in
                        section 7.4.
                    </p>

                </details>
                <details>
                    <summary class="sum2">
                        The Birthday Problem
                    </summary>
                    <figure>
                        <img
                         src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Birthday_candles.jpg/250px-Birthday_candles.jpg">
                        <figcaption>
                        </figcaption>
                    </figure>
                    <p>
                        How many people have to enter a party before it is
                        likely (p &gt; .5) that two of them have the same 
                        birthday?
                        <br />
                        Note that this <i>resembles</i> a pigeonhole problem,
                        but with an important difference: we are not asking how
                        many do we need to be <i>certain</i> two have the same
                        birthday (answer: 367), but how many do we need for it
                        to be <i>likely</i>?
                    </p>
                    <p>
                        We are going to solve this by solving the complement
                        of the problem: we will solve for <i>p<sub>n</sub></i>,
                        the probability that they all have different birthdays,
                        and then the probability two will have the same
                        birthday will be 1 &minus; <i>p<sub>n</sub></i>.
                        The first person obviously will not have "the same"
                        birthday as anyone else. The probability the 
                        second person will have a different birthday is 
                        365 / 366. For the third (assuming no match yet!)
                        it is 364 / 366. And so on.
                    </p>
                    <p>
                        So our question becomes, at what point does 
                        1 &minus; <i>p<sub>n</sub></i> become greater 
                        than .5? And the answer is the surprisingly small
                        number 23!
                        <br />
                        All of this would be just a curiosity, except it
                        is the same question as "How likely is it our
                        hashing function will produce a collision after
                        hashing <i>n</i> items?"
                        <br />
                        In hashing, we are mapping <i>n</i> keys to
                        <i>m</i> slots, where <i>n</i> is usually
                        much greater than <i>m</i>. (For instance, possible
                        student names to 100 slots in a class roster.)
                        We want to know if students are randomly mapped
                        to a slot with probability 1/<i>m</i>, how likely
                        is it that two students will map to the same slot?
                        (Too many collisions slow down our hashing algorithm.)
                    </p>
                </details>

                <details>
                    <summary class="sum2">
                        Monte Carlo Algorithms
                    </summary>
                    <figure>
                        <img
                        src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Roulette_casino.JPG/1024px-Roulette_casino.JPG"
                         height="300" width="400">
                        <figcaption>
                        </figcaption>
                    </figure>
                    <p>
                        These are examples of <i>probabilistic 
                        algorithms</i>. Most of the time, we study 
                        algorithms that produce a definite answer.
                        But probabilistic algorithms produce correct
                        answers only with some likelihood.
                        A <i>Monte Carlo Algorithm</i> runs repeated 
                        trials of some process until the answer it gives is
                        "close enough" to certainty for the purposes of
                        the person or persons employing the algorithm.
                    </p>

                    <p>
                        <b>Example</b>: For an integer that is not prime, it
                        will pass Miller's test for fewer than <i>n</i>/4 bases
                        <i>b</i> with 1 &lt; <i>b</i> &lt; <i>n</i>. We can
                        generate a large number and try, say, <i>k</i>
                        iterations of the algorithm, and if it passes each 
                        iteration, the that it is not prime are
                        (1/4)<sup><i>k</i></sup>. For 30 iterations, this will
                        give us a probability that <i>n</i> is composite
                        of less than 1/10<sup>18</sup>.
                    </p>

                </details>
                <details>
                    <summary class="sum2">
                        The Probabilistic Method
                        <br />
                        Not Covered Fall 2017
                    </summary>

                    <p class="def">
                        THEOREM 3
                    </p>

                    <p class="def">
                        THEOREM 4
                    </p>

                </details>
            </details>

            <details>
                <summary class="sum1">
                Bayes' Theorem 
                <br />
                NOT COVERED FALL 2017
                </summary>
                <details>
                    <summary class="sum2">
                        THEOREM 1
                    </summary>
                </details>
                <details>
                    <summary class="sum2">
                        THEOREM 2
                    </summary>
                </details>
                <details>
                    <summary class="sum2">
                        Bayesian Spam Filter
                    </summary>
                </details>
            </details>

            <details>
                <summary class="sum1">
                Expected Value and Variance 
                </summary>
                <details>
                    <summary class="sum2">
                        Expected Values
                    </summary>
                   
                    <p class="def">
                        DEFINITION 1
                    </p>
                    
                    <p>
                       The expected value of the random variable<i> X</i>on the
                       sample space <i>S</i>, is
                        <i>E</i>(<i>X</i>) = &Sigma;<i>p</i>(<i>s</i>)
                        <i>X</i>(<i>s</i>)
                        <br />
                        This is also called the <i>mean</i> of the random
                        variable.
                        <br />
                        <b>Example:</b> The expected value of 1 toss of 
                        a fair die is 7/2.
                    </p>

              
                    <p class="def">
                        THEOREM 1
                    </p>
               
                    <p>
                        We can also get the above by summing up the
                        probability-weighted values for <i>X</i> being
                        equal to each outcome.
                        <br />
                        <b>Example:</b>
                        Use two coin tosses to illustrate this.
                    </p>

                
                    <p class="def">
                        THEOREM 2
                    </p>
                    <p>
                        The expected number of successes in <i>n</i>
                        Bernoulli trials where the probability of 
                        success in each trial is <i>p</i> = 
                            <i>np</i>.
                        <br />
                        <b>Example:</b>
                        The expected number of sixes in 36 dice rolls
                        (where six is success and all other results failure)
                        is six. (1/6 * 36)
                    </p>

                </details>
                <details>
                    <summary class="sum2">
                        Linearity of Expectations
                    </summary>   

                    <p class="def">
                        THEOREM 3
                    </p>
                    <p>
                        <i>E</i>&Sigma;(<i>X</i><sub>1</sub> + 
                        <i>X</i><sub>2</sub> + ... +
                        <i>X</i><sub>n</sub>
                        = &Sigma;(
                            <i>E</i>(<i>X</i><sub>1</sub>) + 
                            <i>E</i>(<i>X</i><sub>2</sub>) + ... +
                            <i>E</i>(<i>X</i><sub>n</sub>))
                    </p>

                    <p>
                        <b>Expected value in the hatcheck problem</b>:
                        The hatcheck employee loses all tickets and gives the
                        hats back randomly. What is the expected number of
                        people who get back the correct hat?
                    </p>


                </details>
                <details>
                    <summary class="sum2">
                        Average-Case Computational Complexity
                    </summary>
                    <summary class="sum3">
                        Overview
                    </summary>
                      <p>Average case computational complexity of an algorithm is amount of computational resourse used by algorithm,averaged over all possible inputs.It can also be                               interpreted as computing the expected value of a random variable.</p>
                       <p>Let us consider a<sub>j</sub>, j=1,2,....k to be all the outcomes of an experiment and <i>X</i> be a random variable,that defines number of operations used by the                                 algorithm,when a<sub>j</sub> is an input</p><p>Let x<sub>1</sub>,x<sub>2</sub>...x<sub>k</sub> be the respective random variables p<sub>j</sub> is the probability to                         each possible input .Then the average case complexity of the algorithm is</p>

                    <figure>
                        <img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d67d86418d069a861449610af313dfbc208fbd14">
                        <figcaption>
                        </figcaption>
                    </figure>

                </details>
                <details>
                    <summary class="sum2">
                        The Geometric Distribution
                    </summary>
                    <p>Geometric distribution defines random variables with infinitely many outcomes</p>
                      <p class="def">
                        DEFINITION 2
                      </p>
                     <p>A random variable <i>X</i> has a geometric distribution with parameter p if <i>p(X = k) = (1 − p)<sup>k−1</sup></i> p for k = 1, 2, 3, . . ., where p is a real number with                       0 &le;p &le; 1.</p>
                    <p class="def">
                        THEOREM 4
                    </p>
                    <p>If the random variable <i>X</i> has the geometric distribution with parameter p, then <i>E(X) = 1/p.</i></p>
                </details>
                <details>
                    <summary class="sum2">
                        Independent Random Variables
                    </summary>
                    <p>
                    Two random variables <i>X</i> and <i>Y</i>
                    are independent if:
                    <i>p</i>(<i>X</i> = <i>r</i><sub>1</sub> and
                    <i>Y</i> = <i>r</i><sub>2</sub>) =
                    <i>p</i>(<i>X</i> = <i>r</i><sub>1</sub>) *
                    <i>p</i>(<i>Y</i> = <i>r</i><sub>2</sub>)
                    </p>

                </details>

                <details>
                    <summary class="sum2">
                        Variance
                    </summary>
                    <p>The variance of a random variable defines how widely a random variable is distributed</p>

                    <p class="def">
                        DEFINITION 4
                    </p>
                     <p>Let <i> X</i> be a random variable on a sample space <i>S</i>. The variance of <i>X</i>, denoted by <i>V(X)</i>, is V(X) =&sum;<sub> s∈S </sub>(X(s) &minus;                               E(X))<sup>2</sup> p(s).</p><p>That is, V (X) is the weighted average of the square of the deviation of <i>X</i>. The standard deviation of <i>X</i>, denoted σ(X), is defined to be</p>
                      <p><span style="white-space: nowrap;">&radic;<span style="text-decoration:overline;">&nbsp;V(X)&nbsp;</span></span></p>
                    <p class="def">
                        THEOREM 6
                    </p>
                    <p>If <i>X</i> is a random variable on a sample space <i>S</i>, then V(X)= E(X<sup>2</sup>) &minus; E(X)<sup>2</sup>.</p>
                    <p class="def">
                        COROLLARY 1
                    </p>

                    <p>
                        If <i>X</i> is a random variable,
                        <i>V</i>(<i>X</i>) = <i>E</i>((<i>X</i>
                        &minus; <i>&mu;</i>)<sup>2</sup>) 
                    </p>


                    <p class="def">
                        THEOREM 7
                    </p>
                     <p>BIENAYMÉ’S FORMULA If <i>X</i> and <i>Y</i> are two independent      random variables on a sample space <i> S</i>, then <i>V (X + Y)</i> = <i>V (X)</i> +<i> V (Y).</i> Furthermore, if <i>Xi</i>, i = 1, 2, . . . , n, with n a positive integer, are pairwise independent random variables on <i>S</i>, then<i> V (X<sub>1</sub> + X<sub>2</sub> +· · ·+X<sub>n</sub>) = V (X1) + V (X2)+· · ·+V (Xn)</i>.</p>

                    <details>
                        <summary class="sum3">
                            Chebyshev's Inequality
                        </summary>
                        <p>It defines the likeliness of a random variable to take a value far from it's expected value</p>
                        <p class="def">
                             THEOREM 8
                        </p>        
                        <p>Let <i>X</i> be a random variable on a sample space <i>S</i> with probability function p. If r is a positive real number, then <i>p(|X(s) − E(X)| &ge; r) &le; V (X)/r<sup>2</sup>.</i></p>

                    </details>
                </details>
            </details>
    </body>
</html>
